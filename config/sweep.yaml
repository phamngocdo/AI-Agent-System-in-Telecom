# sweep.yaml
project: telecom-llm-finetuning
name: qlora-with-qwen3-8B
method: grid
program: src/training/trainer.py

metric:
  name: eval/loss
  goal: minimize

parameters:
  learning_rate:
    values: [2e-5, 5e-5, 1e-4]
  lora_r:
    value: 16
  gradient_accumulation_steps:
    value: 4

  model_name:
    value: "unsloth/Qwen3-8B-Base-unsloth-bnb-4bit"
  num_train_epochs:
    value: 1
  per_device_train_batch_size:
    value: 4
  max_seq_length:
    value: 1024
  lora_alpha:
    value: 32
  lr_scheduler_type:
    value: "linear"
  weight_decay:
    value: 0.01
  warmup_ratio:
    value: 0.1
  seed:
    value: 42

  eval_strategy:
    value: "steps"
  eval_steps:
    value: 50 
  logging_steps:
    value: 50 
  save_strategy:
    value: "steps"
  save_steps:
    value: 50
  save_total_limit:
    value: 3